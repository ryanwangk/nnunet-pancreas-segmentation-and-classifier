{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ChaI4RPmOsE",
        "outputId": "450c3e85-7a5d-459f-96c7-635474252bd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nnunetv2 dynamic-network-architectures wandb nibabel SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJZ0C6KJ2slK",
        "outputId": "4ce60682-99aa-4358-ec03-6dfbe950fd5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/211.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m211.5/211.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, glob, csv, json\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rVvuOLXyEOom"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "9Of5g-3mGAgO",
        "outputId": "fea91e49-c33b-4d90-e680-9a34afc967e7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryanwangk\u001b[0m (\u001b[33mryanwangk-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ID = 310\n",
        "DATASET_NAME = f\"Dataset{DATASET_ID}_Pancreas\"\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/PC-Classifier\"\n",
        "RAW_DIR = f\"{BASE_DIR}/nnUNet_raw\"\n",
        "PREPROC_DIR = f\"{BASE_DIR}/nnUNet_preprocessed\"\n",
        "RESULTS_DIR = f\"{BASE_DIR}/nnUNet_results\"\n",
        "\n",
        "os.environ[\"nnUNet_raw\"] = RAW_DIR\n",
        "os.environ[\"nnUNet_preprocessed\"] = PREPROC_DIR\n",
        "os.environ[\"nnUNet_results\"] = RESULTS_DIR\n",
        "SRC_DIR = \"/content/drive/MyDrive/ML-Quiz-3DMedImg\"\n",
        "DST_DIR = f\"{RAW_DIR}/{DATASET_NAME}\"\n",
        "os.environ[\"PCCLS_LABELS\"] = f\"{DST_DIR}/subtype_labels.csv\""
      ],
      "metadata": {
        "id": "45qmLmz4UUu6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p $RAW_DIR $PREPROC_DIR $RESULTS_DIR\n",
        "!mkdir -p {DST_DIR}/imagesTr {DST_DIR}/labelsTr {DST_DIR}/imagesTs {DST_DIR}/imagesVal {DST_DIR}/labelsVal"
      ],
      "metadata": {
        "id": "Rr2oJ2tjUfiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "for subtype in [\"subtype0\", \"subtype1\", \"subtype2\"]:\n",
        "    src_path = f\"{SRC_DIR}/train/{subtype}\"\n",
        "    imgs = glob.glob(f\"{src_path}/*_0000.nii.gz\")\n",
        "    for img in imgs:\n",
        "        mask = img.replace(\"_0000.nii.gz\", \".nii.gz\")\n",
        "        shutil.copy(img, f\"{DST_DIR}/imagesTr/\")\n",
        "        shutil.copy(mask, f\"{DST_DIR}/labelsTr/\")\n",
        "\n",
        "#Validate\n",
        "for subtype in [\"subtype0\", \"subtype1\", \"subtype2\"]:\n",
        "    src_path = f\"{SRC_DIR}/validation/{subtype}\"\n",
        "    imgs = glob.glob(f\"{src_path}/*_0000.nii.gz\")\n",
        "    for img in imgs:\n",
        "        mask = img.replace(\"_0000.nii.gz\", \".nii.gz\")\n",
        "        shutil.copy(img, f\"{DST_DIR}/imagesVal/\")\n",
        "        shutil.copy(mask, f\"{DST_DIR}/labelsVal/\")\n",
        "\n",
        "#Test\n",
        "for img in glob.glob(f\"{SRC_DIR}/test/*.nii.gz\"):\n",
        "    shutil.copy(img, f\"{DST_DIR}/imagesTs/\")"
      ],
      "metadata": {
        "id": "BiPHhG1eU5h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = f\"{DST_DIR}/subtype_labels.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Filename\", \"Subtype\"])\n",
        "    for subtype in [\"subtype0\", \"subtype1\", \"subtype2\"]:\n",
        "        for split in [\"train\"]:\n",
        "            imgs = glob.glob(f\"{SRC_DIR}/{split}/{subtype}/*_0000.nii.gz\")\n",
        "            for img in imgs:\n",
        "                base = os.path.basename(img).replace(\"_0000.nii.gz\", \"\")\n",
        "                writer.writerow([base, subtype[-1]])"
      ],
      "metadata": {
        "id": "99AoM1XUVYVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training = len([f for f in os.listdir(f\"{DST_DIR}/imagesTr\") if f.endswith(\".nii.gz\")])\n",
        "num_test = len([f for f in os.listdir(f\"{DST_DIR}/imagesTs\") if f.endswith(\".nii.gz\")])\n",
        "\n",
        "dataset_json = {\n",
        "    \"channel_names\": {\n",
        "        \"0\": \"CT\"\n",
        "    },\n",
        "    \"labels\": {\n",
        "        \"background\": 0,\n",
        "        \"pancreas\": 1,\n",
        "        \"lesion\": 2\n",
        "    },\n",
        "    \"numTraining\": num_training,\n",
        "    \"file_ending\": \".nii.gz\",\n",
        "    \"converted_by\": \"Ryan Khalloqi\"\n",
        "}\n",
        "\n",
        "json_path = f\"{DST_DIR}/dataset.json\"\n",
        "with open(json_path, \"w\") as f:\n",
        "    json.dump(dataset_json, f, indent=4)\n",
        "\n",
        "print(json.dumps(dataset_json, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veHTaA6JX3_C",
        "outputId": "e1c15199-2620-4ad0-d7ce-cd9e84e26402"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"channel_names\": {\n",
            "        \"0\": \"CT\"\n",
            "    },\n",
            "    \"labels\": {\n",
            "        \"background\": 0,\n",
            "        \"pancreas\": 1,\n",
            "        \"lesion\": 2\n",
            "    },\n",
            "    \"numTraining\": 252,\n",
            "    \"file_ending\": \".nii.gz\",\n",
            "    \"converted_by\": \"Ryan Khalloqi\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Check"
      ],
      "metadata": {
        "id": "L6_p5NrRX8IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#round pixel vals\n",
        "\n",
        "label_dirs = [\n",
        "    f\"{DST_DIR}/labelsTr\",\n",
        "    f\"{DST_DIR}/labelsVal\"\n",
        "]\n",
        "\n",
        "for label_dir in label_dirs:\n",
        "    for path in glob.glob(f\"{label_dir}/*.nii.gz\"):\n",
        "        img = nib.load(path)\n",
        "        data = img.get_fdata()\n",
        "\n",
        "        data = np.rint(data).astype(np.uint8)\n",
        "        data[data > 2] = 2\n",
        "        data[data < 0] = 0\n",
        "\n",
        "        nib.save(nib.Nifti1Image(data, img.affine, img.header), path)"
      ],
      "metadata": {
        "id": "lBOUOb7WaqU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 310 -pl nnUNetPlannerResEncM --verify_dataset_integrity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV9YL0mKX7AJ",
        "outputId": "b4d67f1e-da1c-419d-a81d-68688269d3d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset310_Pancreas\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "100% 252/252 [00:16<00:00, 14.94it/s]\n",
            "Experiment planning...\n",
            "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [ 59. 118. 181.], 3d_lowres: [59, 118, 181]\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 134, 'patch_size': (np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([118., 181.]), 'spacing': array([0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(64), np.int64(128), np.int64(192)), 'median_image_size_in_voxels': array([ 59., 118., 181.]), 'spacing': array([2.        , 0.73046875, 0.73046875]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((1, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (1, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/drive/MyDrive/PC-Classifier/nnUNet_preprocessed/Dataset310_Pancreas/nnUNetResEncUNetMPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset310_Pancreas\n",
            "Configuration: 2d...\n",
            "100% 252/252 [10:10<00:00,  2.42s/it]\n",
            "Configuration: 3d_fullres...\n",
            "100% 252/252 [02:50<00:00,  1.48it/s]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetResEncUNetMPlans.json of dataset Dataset310_Pancreas. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "s64TovFKw3jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/PC-Classifier/model/multitask_trainer.py /usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/"
      ],
      "metadata": {
        "id": "U69Y5hhIAqMj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/PC-Classifier/model/classification_head.py /usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/"
      ],
      "metadata": {
        "id": "XVEtmGpuBl8x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"\" > /usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/__init__.py"
      ],
      "metadata": {
        "id": "tQzplTNCCbPJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNED0D5FCelJ",
        "outputId": "2d435066-9759-4d55-8bc4-17dcddafa4b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 96\n",
            "-rw-------  1 root root   780 Oct 28 04:14 classification_head.py\n",
            "-rw-r--r--  1 root root     1 Oct 28 04:18 __init__.py\n",
            "-rw-------  1 root root  2344 Oct 28 04:17 multitask_trainer.py\n",
            "-rw-r--r--  1 root root 71846 Oct 28 03:46 nnUNetTrainer.py\n",
            "drwxr-xr-x  3 root root  4096 Oct 28 03:46 primus\n",
            "drwxr-xr-x  2 root root  4096 Oct 28 04:15 __pycache__\n",
            "drwxr-xr-x 12 root root  4096 Oct 28 03:46 variants\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.12/dist-packages\")\n",
        "\n",
        "from nnunetv2.training.nnUNetTrainer.multitask_trainer import MultiTaskTrainer\n",
        "from nnunetv2.training.nnUNetTrainer.classification_head import ClassificationHead"
      ],
      "metadata": {
        "id": "YRyryYNICmhw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
        "\n",
        "print(inspect.signature(nnUNetTrainer.__init__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWVlLfklE0vk",
        "outputId": "f455c279-2ed0-4783-992e-938c7fd009b3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(self, plans: dict, configuration: str, fold: int, dataset_json: dict, device: torch.device = device(type='cuda'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 310 3d_fullres 0 \\\n",
        "  -p nnUNetResEncUNetMPlans \\\n",
        "  -tr MultiTaskTrainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYxihV7a3_CE",
        "outputId": "efe7d6d3-c2cb-4e84-ce47-5d97a1655206"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "MultiTaskTrainer initialized (network not yet built)\n",
            "2025-10-28 04:39:45.651490: Using torch.compile...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mryanwangk\u001b[0m (\u001b[33mryanwangk-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m猗\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m猓\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251028_043947-wt5wnvd2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mFold0_ResEncM\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at \u001b[34m\u001b[4mhttps://wandb.ai/ryanwangk-university-of-wisconsin-madison/PancreasSegmentation\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/ryanwangk-university-of-wisconsin-madison/PancreasSegmentation/runs/wt5wnvd2\u001b[0m\n",
            "W&B logging started\n",
            "2025-10-28 04:39:48.512138: do_dummy_2d_data_aug: False\n",
            "2025-10-28 04:39:48.527429: Using splits from existing split file: /content/drive/MyDrive/PC-Classifier/nnUNet_preprocessed/Dataset310_Pancreas/splits_final.json\n",
            "2025-10-28 04:39:48.535477: The split file contains 5 splits.\n",
            "2025-10-28 04:39:48.539594: Desired fold for training: 0\n",
            "2025-10-28 04:39:48.543683: This split has 201 training and 51 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 3d_fullres\n",
            " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [64, 128, 192], 'median_image_size_in_voxels': [59.0, 118.0, 181.0], 'spacing': [2.0, 0.73046875, 0.73046875], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset310_Pancreas', 'plans_name': 'nnUNetResEncUNetMPlans', 'original_median_spacing_after_transp': [2.0, 0.73046875, 0.73046875], 'original_median_shape_after_transp': [64, 119, 178], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncM', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1929.0, 'mean': 74.89175415039062, 'median': 78.01163482666016, 'min': -319.0, 'percentile_00_5': -55.99610900878906, 'percentile_99_5': 179.97802734375, 'std': 44.09819793701172}}} \n",
            "\n",
            "2025-10-28 04:39:53.629872: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2025-10-28 04:39:53.701628: \n",
            "2025-10-28 04:39:53.720206: Epoch 0\n",
            "2025-10-28 04:39:53.731349: Current learning rate: 0.01\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/fft_conv_pytorch/fft_conv.py:139: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
            "  output = output[crop_slices].contiguous()\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_inductor/lowering.py:7095: UserWarning: \n",
            "Online softmax is disabled on the fly since Inductor decides to\n",
            "split the reduction. Cut an issue to PyTorch if this is an\n",
            "important use case and you want to speed it up with online\n",
            "softmax.\n",
            "\n",
            "  warnings.warn(\n",
            "2025-10-28 04:42:13.293012: train_loss 0.1739\n",
            "2025-10-28 04:42:13.298674: val_loss 0.07\n",
            "2025-10-28 04:42:13.304133: Pseudo dice [np.float32(0.0), np.float32(0.0)]\n",
            "2025-10-28 04:42:13.309685: Epoch time: 139.61 s\n",
            "2025-10-28 04:42:13.314167: Yayy! New best EMA pseudo Dice: 0.0\n",
            "2025-10-28 04:42:16.234709: \n",
            "2025-10-28 04:42:16.239596: Epoch 1\n",
            "2025-10-28 04:42:16.243378: Current learning rate: 0.00999\n",
            "2025-10-28 04:42:52.635302: train_loss 0.0013\n",
            "2025-10-28 04:42:52.641358: val_loss -0.0498\n",
            "2025-10-28 04:42:52.646757: Pseudo dice [np.float32(0.4231), np.float32(0.0)]\n",
            "2025-10-28 04:42:52.652302: Epoch time: 36.4 s\n",
            "2025-10-28 04:42:52.656922: Yayy! New best EMA pseudo Dice: 0.021199999377131462\n",
            "2025-10-28 04:42:55.759155: \n",
            "2025-10-28 04:42:55.763731: Epoch 2\n",
            "2025-10-28 04:42:55.767895: Current learning rate: 0.00998\n",
            "2025-10-28 04:43:47.464250: train_loss -0.112\n",
            "2025-10-28 04:43:47.471951: val_loss -0.1743\n",
            "2025-10-28 04:43:47.476866: Pseudo dice [np.float32(0.5399), np.float32(0.0)]\n",
            "2025-10-28 04:43:47.481660: Epoch time: 51.71 s\n",
            "2025-10-28 04:43:47.485603: Yayy! New best EMA pseudo Dice: 0.04600000008940697\n",
            "2025-10-28 04:43:50.926303: \n",
            "2025-10-28 04:43:50.930217: Epoch 3\n",
            "2025-10-28 04:43:50.934586: Current learning rate: 0.00997\n",
            "2025-10-28 04:44:42.833632: train_loss -0.2388\n",
            "2025-10-28 04:44:42.839691: val_loss -0.2894\n",
            "2025-10-28 04:44:42.844722: Pseudo dice [np.float32(0.6047), np.float32(0.4543)]\n",
            "2025-10-28 04:44:42.850207: Epoch time: 51.91 s\n",
            "2025-10-28 04:44:42.854289: Yayy! New best EMA pseudo Dice: 0.09440000355243683\n",
            "2025-10-28 04:44:46.201995: \n",
            "2025-10-28 04:44:46.206129: Epoch 4\n",
            "2025-10-28 04:44:46.209727: Current learning rate: 0.00996\n",
            "2025-10-28 04:45:37.241119: train_loss -0.3214\n",
            "2025-10-28 04:45:37.246668: val_loss -0.2754\n",
            "2025-10-28 04:45:37.251303: Pseudo dice [np.float32(0.5825), np.float32(0.3904)]\n",
            "2025-10-28 04:45:37.255424: Epoch time: 51.04 s\n",
            "2025-10-28 04:45:37.259075: Yayy! New best EMA pseudo Dice: 0.13359999656677246\n",
            "2025-10-28 04:45:40.730673: \n",
            "2025-10-28 04:45:40.735465: Epoch 5\n",
            "2025-10-28 04:45:40.739166: Current learning rate: 0.00995\n",
            "2025-10-28 04:46:31.331012: train_loss -0.3713\n",
            "2025-10-28 04:46:31.337058: val_loss -0.3229\n",
            "2025-10-28 04:46:31.341703: Pseudo dice [np.float32(0.6982), np.float32(0.4539)]\n",
            "2025-10-28 04:46:31.346625: Epoch time: 50.6 s\n",
            "2025-10-28 04:46:31.350884: Yayy! New best EMA pseudo Dice: 0.1777999997138977\n",
            "2025-10-28 04:46:34.730788: \n",
            "2025-10-28 04:46:34.734858: Epoch 6\n",
            "2025-10-28 04:46:34.738541: Current learning rate: 0.00995\n",
            "2025-10-28 04:47:25.821553: train_loss -0.4227\n",
            "2025-10-28 04:47:25.826981: val_loss -0.3775\n",
            "2025-10-28 04:47:25.831398: Pseudo dice [np.float32(0.6701), np.float32(0.4532)]\n",
            "2025-10-28 04:47:25.835337: Epoch time: 51.09 s\n",
            "2025-10-28 04:47:25.839069: Yayy! New best EMA pseudo Dice: 0.21619999408721924\n",
            "2025-10-28 04:47:29.177714: \n",
            "2025-10-28 04:47:29.181906: Epoch 7\n",
            "2025-10-28 04:47:29.185549: Current learning rate: 0.00994\n",
            "2025-10-28 04:48:20.533799: train_loss -0.4512\n",
            "2025-10-28 04:48:20.540845: val_loss -0.3981\n",
            "2025-10-28 04:48:20.547148: Pseudo dice [np.float32(0.6889), np.float32(0.4706)]\n",
            "2025-10-28 04:48:20.554585: Epoch time: 51.36 s\n",
            "2025-10-28 04:48:20.562957: Yayy! New best EMA pseudo Dice: 0.2526000142097473\n",
            "2025-10-28 04:48:23.811772: \n",
            "2025-10-28 04:48:23.817314: Epoch 8\n",
            "2025-10-28 04:48:23.821856: Current learning rate: 0.00993\n",
            "2025-10-28 04:49:15.986618: train_loss -0.4775\n",
            "2025-10-28 04:49:15.994198: val_loss -0.4027\n",
            "2025-10-28 04:49:15.999241: Pseudo dice [np.float32(0.7195), np.float32(0.5266)]\n",
            "2025-10-28 04:49:16.004364: Epoch time: 52.18 s\n",
            "2025-10-28 04:49:16.008741: Yayy! New best EMA pseudo Dice: 0.2896000146865845\n",
            "2025-10-28 04:49:19.396565: \n",
            "2025-10-28 04:49:19.400434: Epoch 9\n",
            "2025-10-28 04:49:21.555268: Current learning rate: 0.00992\n",
            "2025-10-28 04:50:12.797468: train_loss -0.4683\n",
            "2025-10-28 04:50:12.802750: val_loss -0.4242\n",
            "2025-10-28 04:50:12.807646: Pseudo dice [np.float32(0.7223), np.float32(0.5539)]\n",
            "2025-10-28 04:50:12.811907: Epoch time: 53.4 s\n",
            "2025-10-28 04:50:12.815589: Yayy! New best EMA pseudo Dice: 0.3244999945163727\n",
            "2025-10-28 04:50:16.259274: \n",
            "2025-10-28 04:50:16.264231: Epoch 10\n",
            "2025-10-28 04:50:16.813508: Current learning rate: 0.00991\n",
            "2025-10-28 04:51:08.428425: train_loss -0.4797\n",
            "2025-10-28 04:51:08.433148: val_loss -0.4392\n",
            "2025-10-28 04:51:08.438001: Pseudo dice [np.float32(0.7604), np.float32(0.4785)]\n",
            "2025-10-28 04:51:08.442321: Epoch time: 52.17 s\n",
            "2025-10-28 04:51:08.445968: Yayy! New best EMA pseudo Dice: 0.3540000021457672\n",
            "2025-10-28 04:51:11.751268: \n",
            "2025-10-28 04:51:11.755484: Epoch 11\n",
            "2025-10-28 04:51:13.911100: Current learning rate: 0.0099\n",
            "2025-10-28 04:52:05.083504: train_loss -0.5235\n",
            "2025-10-28 04:52:05.089558: val_loss -0.5028\n",
            "2025-10-28 04:52:05.094282: Pseudo dice [np.float32(0.7717), np.float32(0.5902)]\n",
            "2025-10-28 04:52:05.098780: Epoch time: 53.34 s\n",
            "2025-10-28 04:52:05.103024: Yayy! New best EMA pseudo Dice: 0.38670000433921814\n",
            "2025-10-28 04:52:08.455839: \n",
            "2025-10-28 04:52:08.459966: Epoch 12\n",
            "2025-10-28 04:52:08.463698: Current learning rate: 0.00989\n",
            "2025-10-28 04:52:59.249619: train_loss -0.5478\n",
            "2025-10-28 04:52:59.265388: val_loss -0.5102\n",
            "2025-10-28 04:52:59.269857: Pseudo dice [np.float32(0.7808), np.float32(0.6093)]\n",
            "2025-10-28 04:52:59.274124: Epoch time: 50.8 s\n",
            "2025-10-28 04:52:59.277988: Yayy! New best EMA pseudo Dice: 0.41749998927116394\n",
            "2025-10-28 04:53:02.597766: \n",
            "2025-10-28 04:53:02.602554: Epoch 13\n",
            "2025-10-28 04:53:02.606289: Current learning rate: 0.00988\n",
            "2025-10-28 04:53:53.479207: train_loss -0.5522\n",
            "2025-10-28 04:53:53.484743: val_loss -0.4742\n",
            "2025-10-28 04:53:53.490146: Pseudo dice [np.float32(0.7501), np.float32(0.5446)]\n",
            "2025-10-28 04:53:53.495643: Epoch time: 50.89 s\n",
            "2025-10-28 04:53:53.499489: Yayy! New best EMA pseudo Dice: 0.4404999911785126\n",
            "2025-10-28 04:53:57.580719: \n",
            "2025-10-28 04:53:57.584871: Epoch 14\n",
            "2025-10-28 04:53:57.589294: Current learning rate: 0.00987\n",
            "2025-10-28 04:54:48.827083: train_loss -0.5499\n",
            "2025-10-28 04:54:48.832164: val_loss -0.4702\n",
            "2025-10-28 04:54:48.836544: Pseudo dice [np.float32(0.7745), np.float32(0.5398)]\n",
            "2025-10-28 04:54:48.840618: Epoch time: 51.25 s\n",
            "2025-10-28 04:54:48.844360: Yayy! New best EMA pseudo Dice: 0.46209999918937683\n",
            "2025-10-28 04:54:52.153204: \n",
            "2025-10-28 04:54:52.157644: Epoch 15\n",
            "2025-10-28 04:54:52.161361: Current learning rate: 0.00986\n",
            "2025-10-28 04:55:43.612183: train_loss -0.572\n",
            "2025-10-28 04:55:43.617514: val_loss -0.4929\n",
            "2025-10-28 04:55:43.622063: Pseudo dice [np.float32(0.7787), np.float32(0.5779)]\n",
            "2025-10-28 04:55:43.626870: Epoch time: 51.46 s\n",
            "2025-10-28 04:55:43.630892: Yayy! New best EMA pseudo Dice: 0.4837999939918518\n",
            "2025-10-28 04:55:47.046212: \n",
            "2025-10-28 04:55:47.049961: Epoch 16\n",
            "2025-10-28 04:55:47.054535: Current learning rate: 0.00986\n",
            "2025-10-28 04:56:38.332502: train_loss -0.5528\n",
            "2025-10-28 04:56:38.337738: val_loss -0.5191\n",
            "2025-10-28 04:56:38.342539: Pseudo dice [np.float32(0.809), np.float32(0.6358)]\n",
            "2025-10-28 04:56:38.347265: Epoch time: 51.29 s\n",
            "2025-10-28 04:56:38.351517: Yayy! New best EMA pseudo Dice: 0.5076000094413757\n",
            "2025-10-28 04:56:41.410311: \n",
            "2025-10-28 04:56:41.414392: Epoch 17\n",
            "2025-10-28 04:56:43.572081: Current learning rate: 0.00985\n",
            "2025-10-28 04:57:33.981520: train_loss -0.5933\n",
            "2025-10-28 04:57:33.987100: val_loss -0.5664\n",
            "2025-10-28 04:57:33.992348: Pseudo dice [np.float32(0.8219), np.float32(0.6505)]\n",
            "2025-10-28 04:57:33.996734: Epoch time: 52.57 s\n",
            "2025-10-28 04:57:34.000692: Yayy! New best EMA pseudo Dice: 0.5304999947547913\n",
            "2025-10-28 04:57:39.174436: \n",
            "2025-10-28 04:57:39.178364: Epoch 18\n",
            "2025-10-28 04:57:39.182072: Current learning rate: 0.00984\n",
            "2025-10-28 04:58:29.778230: train_loss -0.5937\n",
            "2025-10-28 04:58:29.784659: val_loss -0.5636\n",
            "2025-10-28 04:58:29.789408: Pseudo dice [np.float32(0.8154), np.float32(0.6182)]\n",
            "2025-10-28 04:58:29.794132: Epoch time: 50.61 s\n",
            "2025-10-28 04:58:29.798173: Yayy! New best EMA pseudo Dice: 0.5490999817848206\n",
            "2025-10-28 04:58:32.847587: \n",
            "2025-10-28 04:58:32.851513: Epoch 19\n",
            "2025-10-28 04:58:32.855278: Current learning rate: 0.00983\n",
            "2025-10-28 04:59:24.156805: train_loss -0.5955\n",
            "2025-10-28 04:59:24.162422: val_loss -0.5315\n",
            "2025-10-28 04:59:24.166679: Pseudo dice [np.float32(0.7986), np.float32(0.618)]\n",
            "2025-10-28 04:59:24.177660: Epoch time: 51.31 s\n",
            "2025-10-28 04:59:24.181715: Yayy! New best EMA pseudo Dice: 0.5649999976158142\n",
            "2025-10-28 04:59:29.448929: \n",
            "2025-10-28 04:59:29.453597: Epoch 20\n",
            "2025-10-28 04:59:29.457584: Current learning rate: 0.00982\n",
            "2025-10-28 05:00:20.895009: train_loss -0.6152\n",
            "2025-10-28 05:00:20.900798: val_loss -0.5163\n",
            "2025-10-28 05:00:20.905654: Pseudo dice [np.float32(0.7943), np.float32(0.6434)]\n",
            "2025-10-28 05:00:20.910406: Epoch time: 51.45 s\n",
            "2025-10-28 05:00:20.914355: Yayy! New best EMA pseudo Dice: 0.5803999900817871\n",
            "2025-10-28 05:00:26.190697: \n",
            "2025-10-28 05:00:26.194851: Epoch 21\n",
            "2025-10-28 05:00:26.198475: Current learning rate: 0.00981\n",
            "2025-10-28 05:01:17.630671: train_loss -0.6019\n",
            "2025-10-28 05:01:17.637797: val_loss -0.5665\n",
            "2025-10-28 05:01:17.642434: Pseudo dice [np.float32(0.8349), np.float32(0.6281)]\n",
            "2025-10-28 05:01:17.647016: Epoch time: 51.44 s\n",
            "2025-10-28 05:01:17.663903: Yayy! New best EMA pseudo Dice: 0.5954999923706055\n",
            "2025-10-28 05:01:20.715586: \n",
            "2025-10-28 05:01:20.719487: Epoch 22\n",
            "2025-10-28 05:01:20.723307: Current learning rate: 0.0098\n",
            "2025-10-28 05:02:11.386584: train_loss -0.608\n",
            "2025-10-28 05:02:11.392554: val_loss -0.5297\n",
            "2025-10-28 05:02:11.408907: Pseudo dice [np.float32(0.8007), np.float32(0.5809)]\n",
            "2025-10-28 05:02:11.414215: Epoch time: 50.67 s\n",
            "2025-10-28 05:02:11.418733: Yayy! New best EMA pseudo Dice: 0.6050999760627747\n",
            "2025-10-28 05:02:14.523929: \n",
            "2025-10-28 05:02:14.527878: Epoch 23\n",
            "2025-10-28 05:02:14.531556: Current learning rate: 0.00979\n",
            "2025-10-28 05:03:05.552435: train_loss -0.6111\n",
            "2025-10-28 05:03:05.557945: val_loss -0.5658\n",
            "2025-10-28 05:03:05.562232: Pseudo dice [np.float32(0.8285), np.float32(0.643)]\n",
            "2025-10-28 05:03:05.567184: Epoch time: 51.03 s\n",
            "2025-10-28 05:03:05.582673: Yayy! New best EMA pseudo Dice: 0.6180999875068665\n",
            "2025-10-28 05:03:08.891914: \n",
            "2025-10-28 05:03:08.896110: Epoch 24\n",
            "2025-10-28 05:03:08.899837: Current learning rate: 0.00978\n",
            "2025-10-28 05:04:00.301595: train_loss -0.6192\n",
            "2025-10-28 05:04:00.306784: val_loss -0.5392\n",
            "2025-10-28 05:04:00.311612: Pseudo dice [np.float32(0.8124), np.float32(0.6252)]\n",
            "2025-10-28 05:04:00.316350: Epoch time: 51.41 s\n",
            "2025-10-28 05:04:00.320628: Yayy! New best EMA pseudo Dice: 0.6281999945640564\n",
            "2025-10-28 05:04:03.839820: \n",
            "2025-10-28 05:04:03.844637: Epoch 25\n",
            "2025-10-28 05:04:03.848407: Current learning rate: 0.00977\n",
            "2025-10-28 05:04:55.068022: train_loss -0.6245\n",
            "2025-10-28 05:04:55.083819: val_loss -0.5453\n",
            "2025-10-28 05:04:55.089039: Pseudo dice [np.float32(0.8192), np.float32(0.6583)]\n",
            "2025-10-28 05:04:55.094217: Epoch time: 51.23 s\n",
            "2025-10-28 05:04:55.098220: Yayy! New best EMA pseudo Dice: 0.63919997215271\n",
            "2025-10-28 05:04:58.293948: \n",
            "2025-10-28 05:04:58.298059: Epoch 26\n",
            "2025-10-28 05:04:58.301679: Current learning rate: 0.00977\n",
            "2025-10-28 05:05:49.910258: train_loss -0.6451\n",
            "2025-10-28 05:05:49.915452: val_loss -0.5655\n",
            "2025-10-28 05:05:49.920577: Pseudo dice [np.float32(0.8573), np.float32(0.6862)]\n",
            "2025-10-28 05:05:49.925457: Epoch time: 51.62 s\n",
            "2025-10-28 05:05:49.929101: Yayy! New best EMA pseudo Dice: 0.6524999737739563\n",
            "2025-10-28 05:05:53.019585: \n",
            "2025-10-28 05:05:53.023616: Epoch 27\n",
            "2025-10-28 05:05:53.027302: Current learning rate: 0.00976\n",
            "2025-10-28 05:06:44.771573: train_loss -0.6303\n",
            "2025-10-28 05:06:44.777432: val_loss -0.5499\n",
            "2025-10-28 05:06:44.782471: Pseudo dice [np.float32(0.8266), np.float32(0.6451)]\n",
            "2025-10-28 05:06:44.787062: Epoch time: 51.76 s\n",
            "2025-10-28 05:06:44.791910: Yayy! New best EMA pseudo Dice: 0.6607999801635742\n",
            "2025-10-28 05:06:47.887138: \n",
            "2025-10-28 05:06:47.891476: Epoch 28\n",
            "2025-10-28 05:06:47.895315: Current learning rate: 0.00975\n",
            "2025-10-28 05:07:38.455224: train_loss -0.6475\n",
            "2025-10-28 05:07:38.462825: val_loss -0.5333\n",
            "2025-10-28 05:07:38.467708: Pseudo dice [np.float32(0.8033), np.float32(0.639)]\n",
            "2025-10-28 05:07:38.472067: Epoch time: 50.57 s\n",
            "2025-10-28 05:07:38.475962: Yayy! New best EMA pseudo Dice: 0.6668999791145325\n",
            "2025-10-28 05:07:41.515677: \n",
            "2025-10-28 05:07:41.519513: Epoch 29\n",
            "2025-10-28 05:07:41.523645: Current learning rate: 0.00974\n",
            "2025-10-28 05:08:32.976966: train_loss -0.6619\n",
            "2025-10-28 05:08:32.990392: val_loss -0.5889\n",
            "2025-10-28 05:08:32.995332: Pseudo dice [np.float32(0.8474), np.float32(0.6942)]\n",
            "2025-10-28 05:08:33.000376: Epoch time: 51.46 s\n",
            "2025-10-28 05:08:33.004810: Yayy! New best EMA pseudo Dice: 0.677299976348877\n",
            "2025-10-28 05:08:36.107729: \n",
            "2025-10-28 05:08:36.113710: Epoch 30\n",
            "2025-10-28 05:08:36.117519: Current learning rate: 0.00973\n",
            "2025-10-28 05:09:27.234309: train_loss -0.6371\n",
            "2025-10-28 05:09:27.239883: val_loss -0.5922\n",
            "2025-10-28 05:09:27.245243: Pseudo dice [np.float32(0.8466), np.float32(0.6753)]\n",
            "2025-10-28 05:09:27.250680: Epoch time: 51.13 s\n",
            "2025-10-28 05:09:27.254886: Yayy! New best EMA pseudo Dice: 0.6855999827384949\n",
            "2025-10-28 05:09:30.277865: \n",
            "2025-10-28 05:09:30.282596: Epoch 31\n",
            "2025-10-28 05:09:30.286115: Current learning rate: 0.00972\n",
            "2025-10-28 05:10:21.020853: train_loss -0.6522\n",
            "2025-10-28 05:10:21.030471: val_loss -0.5198\n",
            "2025-10-28 05:10:21.035063: Pseudo dice [np.float32(0.8163), np.float32(0.6176)]\n",
            "2025-10-28 05:10:21.039846: Epoch time: 50.75 s\n",
            "2025-10-28 05:10:21.043574: Yayy! New best EMA pseudo Dice: 0.6887999773025513\n",
            "2025-10-28 05:10:25.068222: \n",
            "2025-10-28 05:10:25.072478: Epoch 32\n",
            "2025-10-28 05:10:25.076535: Current learning rate: 0.00971\n",
            "2025-10-28 05:11:16.561682: train_loss -0.6568\n",
            "2025-10-28 05:11:16.567578: val_loss -0.617\n",
            "2025-10-28 05:11:16.571910: Pseudo dice [np.float32(0.8531), np.float32(0.681)]\n",
            "2025-10-28 05:11:16.576399: Epoch time: 51.5 s\n",
            "2025-10-28 05:11:16.580167: Yayy! New best EMA pseudo Dice: 0.6966000199317932\n",
            "2025-10-28 05:11:19.931031: \n",
            "2025-10-28 05:11:19.935519: Epoch 33\n",
            "2025-10-28 05:11:19.939147: Current learning rate: 0.0097\n",
            "2025-10-28 05:12:12.252523: train_loss -0.6687\n",
            "2025-10-28 05:12:12.258355: val_loss -0.5966\n",
            "2025-10-28 05:12:12.263542: Pseudo dice [np.float32(0.8514), np.float32(0.6385)]\n",
            "2025-10-28 05:12:12.268319: Epoch time: 52.32 s\n",
            "2025-10-28 05:12:12.272181: Yayy! New best EMA pseudo Dice: 0.7013999819755554\n",
            "2025-10-28 05:12:15.380136: \n",
            "2025-10-28 05:12:15.384156: Epoch 34\n",
            "2025-10-28 05:12:15.388041: Current learning rate: 0.00969\n",
            "2025-10-28 05:13:06.500025: train_loss -0.6658\n",
            "2025-10-28 05:13:06.506246: val_loss -0.6234\n",
            "2025-10-28 05:13:06.513668: Pseudo dice [np.float32(0.8583), np.float32(0.6898)]\n",
            "2025-10-28 05:13:06.520509: Epoch time: 51.12 s\n",
            "2025-10-28 05:13:06.527027: Yayy! New best EMA pseudo Dice: 0.7087000012397766\n",
            "2025-10-28 05:13:09.670028: \n",
            "2025-10-28 05:13:09.674277: Epoch 35\n",
            "2025-10-28 05:13:09.677818: Current learning rate: 0.00968\n",
            "2025-10-28 05:14:00.416741: train_loss -0.6715\n",
            "2025-10-28 05:14:00.422132: val_loss -0.5944\n",
            "2025-10-28 05:14:00.427408: Pseudo dice [np.float32(0.8453), np.float32(0.6851)]\n",
            "2025-10-28 05:14:00.432330: Epoch time: 50.75 s\n",
            "2025-10-28 05:14:00.435836: Yayy! New best EMA pseudo Dice: 0.7142999768257141\n",
            "2025-10-28 05:14:03.564861: \n",
            "2025-10-28 05:14:03.568864: Epoch 36\n",
            "2025-10-28 05:14:03.572594: Current learning rate: 0.00968\n",
            "2025-10-28 05:14:55.557787: train_loss -0.6726\n",
            "2025-10-28 05:14:55.563812: val_loss -0.6078\n",
            "2025-10-28 05:14:55.568546: Pseudo dice [np.float32(0.8549), np.float32(0.7128)]\n",
            "2025-10-28 05:14:55.573496: Epoch time: 52.0 s\n",
            "2025-10-28 05:14:55.577771: Yayy! New best EMA pseudo Dice: 0.7213000059127808\n",
            "2025-10-28 05:14:58.769991: \n",
            "2025-10-28 05:14:58.774565: Epoch 37\n",
            "2025-10-28 05:14:58.778143: Current learning rate: 0.00967\n",
            "2025-10-28 05:15:49.746281: train_loss -0.6715\n",
            "2025-10-28 05:15:49.751385: val_loss -0.5681\n",
            "2025-10-28 05:15:49.756332: Pseudo dice [np.float32(0.8443), np.float32(0.6309)]\n",
            "2025-10-28 05:15:49.761251: Epoch time: 50.98 s\n",
            "2025-10-28 05:15:49.766587: Yayy! New best EMA pseudo Dice: 0.7228999733924866\n",
            "2025-10-28 05:15:52.966440: \n",
            "2025-10-28 05:15:52.970762: Epoch 38\n",
            "2025-10-28 05:15:52.974896: Current learning rate: 0.00966\n",
            "2025-10-28 05:16:44.275069: train_loss -0.662\n",
            "2025-10-28 05:16:44.280487: val_loss -0.5517\n",
            "2025-10-28 05:16:44.285104: Pseudo dice [np.float32(0.8477), np.float32(0.6293)]\n",
            "2025-10-28 05:16:44.289087: Epoch time: 51.31 s\n",
            "2025-10-28 05:16:44.292960: Yayy! New best EMA pseudo Dice: 0.7245000004768372\n",
            "2025-10-28 05:16:48.532746: \n",
            "2025-10-28 05:16:48.537812: Epoch 39\n",
            "2025-10-28 05:16:48.541822: Current learning rate: 0.00965\n",
            "2025-10-28 05:17:39.551342: train_loss -0.665\n",
            "2025-10-28 05:17:39.556541: val_loss -0.6\n",
            "2025-10-28 05:17:39.561131: Pseudo dice [np.float32(0.849), np.float32(0.7046)]\n",
            "2025-10-28 05:17:39.565201: Epoch time: 51.02 s\n",
            "2025-10-28 05:17:39.569064: Yayy! New best EMA pseudo Dice: 0.7297000288963318\n",
            "2025-10-28 05:17:42.646584: \n",
            "2025-10-28 05:17:42.652650: Epoch 40\n",
            "2025-10-28 05:17:42.657012: Current learning rate: 0.00964\n",
            "2025-10-28 05:18:36.201401: train_loss -0.6779\n",
            "2025-10-28 05:18:36.206802: val_loss -0.5386\n",
            "2025-10-28 05:18:36.211498: Pseudo dice [np.float32(0.8534), np.float32(0.6334)]\n",
            "2025-10-28 05:18:36.215837: Epoch time: 53.56 s\n",
            "2025-10-28 05:18:36.219439: Yayy! New best EMA pseudo Dice: 0.7311000227928162\n",
            "2025-10-28 05:18:41.513207: \n",
            "2025-10-28 05:18:41.517527: Epoch 41\n",
            "2025-10-28 05:18:41.521233: Current learning rate: 0.00963\n",
            "2025-10-28 05:19:32.210659: train_loss -0.6815\n",
            "2025-10-28 05:19:32.219438: val_loss -0.5648\n",
            "2025-10-28 05:19:32.224677: Pseudo dice [np.float32(0.8593), np.float32(0.6017)]\n",
            "2025-10-28 05:19:32.239392: Epoch time: 50.7 s\n",
            "2025-10-28 05:19:33.601637: \n",
            "2025-10-28 05:19:33.605649: Epoch 42\n",
            "2025-10-28 05:19:33.609451: Current learning rate: 0.00962\n",
            "2025-10-28 05:20:08.956196: train_loss -0.6796\n",
            "2025-10-28 05:20:08.962264: val_loss -0.5763\n",
            "2025-10-28 05:20:08.967041: Pseudo dice [np.float32(0.838), np.float32(0.6956)]\n",
            "2025-10-28 05:20:08.971538: Epoch time: 35.36 s\n",
            "2025-10-28 05:20:08.975230: Yayy! New best EMA pseudo Dice: 0.7346000075340271\n",
            "2025-10-28 05:20:12.021401: \n",
            "2025-10-28 05:20:12.025418: Epoch 43\n",
            "2025-10-28 05:20:12.028890: Current learning rate: 0.00961\n",
            "2025-10-28 05:21:04.611363: train_loss -0.6821\n",
            "2025-10-28 05:21:04.617369: val_loss -0.6208\n",
            "2025-10-28 05:21:04.622341: Pseudo dice [np.float32(0.8662), np.float32(0.7024)]\n",
            "2025-10-28 05:21:04.626917: Epoch time: 52.59 s\n",
            "2025-10-28 05:21:04.630820: Yayy! New best EMA pseudo Dice: 0.7396000027656555\n",
            "2025-10-28 05:21:07.722292: \n",
            "2025-10-28 05:21:07.726755: Epoch 44\n",
            "2025-10-28 05:21:07.730128: Current learning rate: 0.0096\n",
            "2025-10-28 05:21:59.598775: train_loss -0.6904\n",
            "2025-10-28 05:21:59.604918: val_loss -0.5962\n",
            "2025-10-28 05:21:59.621990: Pseudo dice [np.float32(0.8542), np.float32(0.6762)]\n",
            "2025-10-28 05:21:59.626852: Epoch time: 51.88 s\n",
            "2025-10-28 05:21:59.630598: Yayy! New best EMA pseudo Dice: 0.7421000003814697\n",
            "2025-10-28 05:22:02.703735: \n",
            "2025-10-28 05:22:02.707495: Epoch 45\n",
            "2025-10-28 05:22:02.711481: Current learning rate: 0.00959\n",
            "2025-10-28 05:22:54.029433: train_loss -0.6978\n",
            "2025-10-28 05:22:54.035681: val_loss -0.5918\n",
            "2025-10-28 05:22:54.053318: Pseudo dice [np.float32(0.8646), np.float32(0.6946)]\n",
            "2025-10-28 05:22:54.058552: Epoch time: 51.33 s\n",
            "2025-10-28 05:22:54.062998: Yayy! New best EMA pseudo Dice: 0.7458999752998352\n",
            "2025-10-28 05:22:57.163810: \n",
            "2025-10-28 05:22:57.167729: Epoch 46\n",
            "2025-10-28 05:22:57.171573: Current learning rate: 0.00959\n",
            "2025-10-28 05:23:48.336182: train_loss -0.6783\n",
            "2025-10-28 05:23:48.349354: val_loss -0.5795\n",
            "2025-10-28 05:23:48.354311: Pseudo dice [np.float32(0.8698), np.float32(0.6495)]\n",
            "2025-10-28 05:23:48.359265: Epoch time: 51.18 s\n",
            "2025-10-28 05:23:48.363363: Yayy! New best EMA pseudo Dice: 0.7473000288009644\n",
            "2025-10-28 05:23:51.665671: \n",
            "2025-10-28 05:23:51.669761: Epoch 47\n",
            "2025-10-28 05:23:51.673257: Current learning rate: 0.00958\n",
            "2025-10-28 05:24:43.075226: train_loss -0.6906\n",
            "2025-10-28 05:24:43.080424: val_loss -0.5674\n",
            "2025-10-28 05:24:43.100970: Pseudo dice [np.float32(0.8408), np.float32(0.6034)]\n",
            "2025-10-28 05:24:43.105971: Epoch time: 51.41 s\n",
            "2025-10-28 05:24:44.472985: \n",
            "2025-10-28 05:24:44.477171: Epoch 48\n",
            "2025-10-28 05:24:44.480878: Current learning rate: 0.00957\n",
            "2025-10-28 05:25:19.871534: train_loss -0.7155\n",
            "2025-10-28 05:25:19.881387: val_loss -0.6117\n",
            "2025-10-28 05:25:19.886274: Pseudo dice [np.float32(0.8645), np.float32(0.6414)]\n",
            "2025-10-28 05:25:19.890596: Epoch time: 35.4 s\n",
            "2025-10-28 05:25:21.254795: \n",
            "2025-10-28 05:25:21.258830: Epoch 49\n",
            "2025-10-28 05:25:21.262369: Current learning rate: 0.00956\n",
            "2025-10-28 05:25:56.844523: train_loss -0.7122\n",
            "2025-10-28 05:25:56.850823: val_loss -0.6152\n",
            "2025-10-28 05:25:56.856866: Pseudo dice [np.float32(0.8579), np.float32(0.7023)]\n",
            "2025-10-28 05:25:56.862756: Epoch time: 35.59 s\n",
            "2025-10-28 05:25:58.601681: Yayy! New best EMA pseudo Dice: 0.7490000128746033\n",
            "2025-10-28 05:26:02.765853: \n",
            "2025-10-28 05:26:02.769933: Epoch 50\n",
            "2025-10-28 05:26:02.773876: Current learning rate: 0.00955\n",
            "2025-10-28 05:26:53.692298: train_loss -0.7051\n",
            "2025-10-28 05:26:53.698481: val_loss -0.6239\n",
            "2025-10-28 05:26:53.703750: Pseudo dice [np.float32(0.8654), np.float32(0.7167)]\n",
            "2025-10-28 05:26:53.709394: Epoch time: 50.93 s\n",
            "2025-10-28 05:26:53.713971: Yayy! New best EMA pseudo Dice: 0.7531999945640564\n",
            "2025-10-28 05:26:57.016863: \n",
            "2025-10-28 05:26:57.021765: Epoch 51\n",
            "2025-10-28 05:26:57.025616: Current learning rate: 0.00954\n",
            "2025-10-28 05:27:48.139013: train_loss -0.6977\n",
            "2025-10-28 05:27:48.146512: val_loss -0.5999\n",
            "2025-10-28 05:27:48.152789: Pseudo dice [np.float32(0.8617), np.float32(0.6823)]\n",
            "2025-10-28 05:27:48.158217: Epoch time: 51.13 s\n",
            "2025-10-28 05:27:48.163533: Yayy! New best EMA pseudo Dice: 0.7551000118255615\n",
            "2025-10-28 05:27:51.266572: \n",
            "2025-10-28 05:27:51.270787: Epoch 52\n",
            "2025-10-28 05:27:51.274628: Current learning rate: 0.00953\n",
            "2025-10-28 05:28:41.999233: train_loss -0.7109\n",
            "2025-10-28 05:28:42.005053: val_loss -0.6043\n",
            "2025-10-28 05:28:42.009625: Pseudo dice [np.float32(0.8644), np.float32(0.715)]\n",
            "2025-10-28 05:28:42.014165: Epoch time: 50.74 s\n",
            "2025-10-28 05:28:42.018182: Yayy! New best EMA pseudo Dice: 0.7585999965667725\n",
            "2025-10-28 05:28:45.103294: \n",
            "2025-10-28 05:28:46.393008: Epoch 53\n",
            "2025-10-28 05:28:46.396735: Current learning rate: 0.00952\n",
            "2025-10-28 05:29:37.393271: train_loss -0.7115\n",
            "2025-10-28 05:29:37.399084: val_loss -0.6116\n",
            "2025-10-28 05:29:37.403856: Pseudo dice [np.float32(0.8772), np.float32(0.7542)]\n",
            "2025-10-28 05:29:37.408309: Epoch time: 52.29 s\n",
            "2025-10-28 05:29:37.412239: Yayy! New best EMA pseudo Dice: 0.7642999887466431\n",
            "2025-10-28 05:29:42.726644: \n",
            "2025-10-28 05:29:42.730863: Epoch 54\n",
            "2025-10-28 05:29:42.734542: Current learning rate: 0.00951\n",
            "2025-10-28 05:30:33.196895: train_loss -0.6946\n",
            "2025-10-28 05:30:33.202661: val_loss -0.5939\n",
            "2025-10-28 05:30:33.207457: Pseudo dice [np.float32(0.8587), np.float32(0.6548)]\n",
            "2025-10-28 05:30:33.211996: Epoch time: 50.47 s\n",
            "2025-10-28 05:30:34.609373: \n",
            "2025-10-28 05:30:34.613869: Epoch 55\n",
            "2025-10-28 05:30:34.617560: Current learning rate: 0.0095\n",
            "2025-10-28 05:31:10.053626: train_loss -0.6922\n",
            "2025-10-28 05:31:10.058370: val_loss -0.5596\n",
            "2025-10-28 05:31:10.062860: Pseudo dice [np.float32(0.8478), np.float32(0.6058)]\n",
            "2025-10-28 05:31:10.080950: Epoch time: 35.45 s\n",
            "2025-10-28 05:31:11.467497: \n",
            "2025-10-28 05:31:11.471457: Epoch 56\n",
            "2025-10-28 05:31:11.474998: Current learning rate: 0.00949\n",
            "2025-10-28 05:31:47.198957: train_loss -0.7176\n",
            "2025-10-28 05:31:47.203960: val_loss -0.6232\n",
            "2025-10-28 05:31:47.208408: Pseudo dice [np.float32(0.8644), np.float32(0.6338)]\n",
            "2025-10-28 05:31:47.212723: Epoch time: 35.73 s\n",
            "2025-10-28 05:31:48.596800: \n",
            "2025-10-28 05:31:48.601662: Epoch 57\n",
            "2025-10-28 05:31:48.605440: Current learning rate: 0.00949\n",
            "2025-10-28 05:32:24.165309: train_loss -0.717\n",
            "2025-10-28 05:32:24.170603: val_loss -0.5944\n",
            "2025-10-28 05:32:24.174845: Pseudo dice [np.float32(0.8693), np.float32(0.6405)]\n",
            "2025-10-28 05:32:24.178910: Epoch time: 35.57 s\n",
            "2025-10-28 05:32:25.540172: \n",
            "2025-10-28 05:32:25.544221: Epoch 58\n",
            "2025-10-28 05:32:25.547667: Current learning rate: 0.00948\n",
            "2025-10-28 05:33:01.016240: train_loss -0.7179\n",
            "2025-10-28 05:33:01.021183: val_loss -0.5796\n",
            "2025-10-28 05:33:01.025722: Pseudo dice [np.float32(0.8445), np.float32(0.6195)]\n",
            "2025-10-28 05:33:01.030391: Epoch time: 35.48 s\n",
            "2025-10-28 05:33:02.411554: \n",
            "2025-10-28 05:33:02.415821: Epoch 59\n",
            "2025-10-28 05:33:02.419326: Current learning rate: 0.00947\n",
            "2025-10-28 05:33:38.357345: train_loss -0.723\n",
            "2025-10-28 05:33:38.363502: val_loss -0.5934\n",
            "2025-10-28 05:33:38.368813: Pseudo dice [np.float32(0.857), np.float32(0.6642)]\n",
            "2025-10-28 05:33:38.373243: Epoch time: 35.95 s\n",
            "2025-10-28 05:33:39.758608: \n",
            "2025-10-28 05:33:39.762650: Epoch 60\n",
            "2025-10-28 05:33:39.777323: Current learning rate: 0.00946\n",
            "2025-10-28 05:34:15.402757: train_loss -0.7198\n",
            "2025-10-28 05:34:15.408665: val_loss -0.5244\n",
            "2025-10-28 05:34:15.413013: Pseudo dice [np.float32(0.8476), np.float32(0.5371)]\n",
            "2025-10-28 05:34:15.417334: Epoch time: 35.65 s\n",
            "2025-10-28 05:34:16.812527: \n",
            "2025-10-28 05:34:16.816432: Epoch 61\n",
            "2025-10-28 05:34:16.820151: Current learning rate: 0.00945\n",
            "2025-10-28 05:34:52.694255: train_loss -0.7225\n",
            "2025-10-28 05:34:52.700252: val_loss -0.5976\n",
            "2025-10-28 05:34:52.707467: Pseudo dice [np.float32(0.8654), np.float32(0.7138)]\n",
            "2025-10-28 05:34:52.712329: Epoch time: 35.88 s\n",
            "2025-10-28 05:34:54.113771: \n",
            "2025-10-28 05:34:54.118673: Epoch 62\n",
            "2025-10-28 05:34:54.122496: Current learning rate: 0.00944\n",
            "2025-10-28 05:35:29.668052: train_loss -0.7353\n",
            "2025-10-28 05:35:29.673585: val_loss -0.6552\n",
            "2025-10-28 05:35:29.678699: Pseudo dice [np.float32(0.8705), np.float32(0.7437)]\n",
            "2025-10-28 05:35:29.682938: Epoch time: 35.56 s\n",
            "2025-10-28 05:35:31.057314: \n",
            "2025-10-28 05:35:31.061280: Epoch 63\n",
            "2025-10-28 05:35:31.064735: Current learning rate: 0.00943\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n",
            "    sys.exit(run_training_entry())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 266, in run_training_entry\n",
            "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/run/run_training.py\", line 207, in run_training\n",
            "    nnunet_trainer.run_training()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1371, in run_training\n",
            "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 994, in train_step\n",
            "    self.grad_scaler.scale(l).backward()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 647, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m:  View run \u001b[33mFold0_ResEncM\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251028_043947-wt5wnvd2/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/drive/MyDrive/PC-Classifier/nnUNet_results/Dataset310_Pancreas/MultiTaskTrainer__nnUNetResEncUNetMPlans__3d_fullres/fold_0/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bgps8psV989",
        "outputId": "dfe9b164-0f1a-49d7-9f89-8ae867de5f79"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.6G\n",
            "-rw------- 1 root root 781M Oct 28 05:29 checkpoint_best.pth\n",
            "-rw------- 1 root root 781M Oct 28 05:25 checkpoint_latest.pth\n",
            "-rw------- 1 root root  13K Oct 28 04:39 debug.json\n",
            "-rw------- 1 root root 541K Oct 28 05:35 progress.png\n",
            "-rw------- 1 root root  404 Oct 28 04:30 training_log_2025_10_28_04_30_04.txt\n",
            "-rw------- 1 root root 3.3K Oct 28 04:31 training_log_2025_10_28_04_31_10.txt\n",
            "-rw------- 1 root root  456 Oct 28 04:37 training_log_2025_10_28_04_37_44.txt\n",
            "-rw------- 1 root root  456 Oct 28 04:38 training_log_2025_10_28_04_38_57.txt\n",
            "-rw------- 1 root root  30K Oct 28 05:34 training_log_2025_10_28_04_39_42.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict \\\n",
        "  -i /content/drive/MyDrive/PC-Classifier/nnUNet_raw/Dataset310_Pancreas/imagesVal \\\n",
        "  -o /content/drive/MyDrive/PC-Classifier/predictions_val \\\n",
        "  -d 310 -c 3d_fullres \\\n",
        "  -p nnUNetResEncUNetMPlans \\\n",
        "  -tr MultiTaskTrainer \\\n",
        "  -f 0 \\\n",
        "  -chk checkpoint_best.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJvzZ-9TVg7i",
        "outputId": "72b0424e-9a30-499b-9342-13b680bcf906"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "There are 36 cases in the source folder\n",
            "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 36 cases that I would like to predict\n",
            "\n",
            "Predicting quiz_0_168:\n",
            "perform_everything_on_device: True\n",
            "100% 4/4 [00:01<00:00,  2.41it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_168\n",
            "\n",
            "Predicting quiz_0_171:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_171\n",
            "\n",
            "Predicting quiz_0_174:\n",
            "perform_everything_on_device: True\n",
            "100% 3/3 [00:00<00:00,  4.54it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_174\n",
            "\n",
            "Predicting quiz_0_184:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_184\n",
            "\n",
            "Predicting quiz_0_187:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_187\n",
            "\n",
            "Predicting quiz_0_189:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_189\n",
            "\n",
            "Predicting quiz_0_244:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_244\n",
            "\n",
            "Predicting quiz_0_253:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_253\n",
            "\n",
            "Predicting quiz_0_254:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_0_254\n",
            "\n",
            "Predicting quiz_1_090:\n",
            "perform_everything_on_device: True\n",
            "100% 4/4 [00:00<00:00,  4.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_090\n",
            "\n",
            "Predicting quiz_1_093:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_093\n",
            "\n",
            "Predicting quiz_1_094:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_094\n",
            "\n",
            "Predicting quiz_1_154:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.62it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_154\n",
            "\n",
            "Predicting quiz_1_158:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_158\n",
            "\n",
            "Predicting quiz_1_164:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_164\n",
            "\n",
            "Predicting quiz_1_166:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_166\n",
            "\n",
            "Predicting quiz_1_211:\n",
            "perform_everything_on_device: True\n",
            "100% 4/4 [00:00<00:00,  4.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_211\n",
            "\n",
            "Predicting quiz_1_213:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_213\n",
            "\n",
            "Predicting quiz_1_221:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.09it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_221\n",
            "\n",
            "Predicting quiz_1_227:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_227\n",
            "\n",
            "Predicting quiz_1_231:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_231\n",
            "\n",
            "Predicting quiz_1_242:\n",
            "perform_everything_on_device: True\n",
            "100% 4/4 [00:00<00:00,  4.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_242\n",
            "\n",
            "Predicting quiz_1_331:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  4.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_331\n",
            "\n",
            "Predicting quiz_1_335:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_1_335\n",
            "\n",
            "Predicting quiz_2_074:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_074\n",
            "\n",
            "Predicting quiz_2_080:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_080\n",
            "\n",
            "Predicting quiz_2_084:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_084\n",
            "\n",
            "Predicting quiz_2_085:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_085\n",
            "\n",
            "Predicting quiz_2_088:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  4.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_088\n",
            "\n",
            "Predicting quiz_2_089:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_089\n",
            "\n",
            "Predicting quiz_2_098:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.66it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_098\n",
            "\n",
            "Predicting quiz_2_191:\n",
            "perform_everything_on_device: True\n",
            "100% 8/8 [00:01<00:00,  4.38it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_191\n",
            "\n",
            "Predicting quiz_2_241:\n",
            "perform_everything_on_device: True\n",
            "100% 4/4 [00:00<00:00,  4.47it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_241\n",
            "\n",
            "Predicting quiz_2_364:\n",
            "perform_everything_on_device: True\n",
            "100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_364\n",
            "\n",
            "Predicting quiz_2_377:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_377\n",
            "\n",
            "Predicting quiz_2_379:\n",
            "perform_everything_on_device: True\n",
            "100% 2/2 [00:00<00:00,  4.67it/s]\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with quiz_2_379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_dir = \"/content/drive/MyDrive/PC-Classifier/predictions_val\"\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/PC-Classifier\"\n",
        "pred_dir = f\"{base_dir}/predictions_val\"\n",
        "input_dir = f\"{base_dir}/nnUNet_raw/Dataset310_Pancreas/imagesVal\"\n",
        "label_dir = f\"{base_dir}/nnUNet_raw/Dataset310_Pancreas/labelsVal\"\n",
        "\n",
        "case = sorted([f for f in os.listdir(pred_dir) if f.endswith(\".nii.gz\")])[0]\n",
        "case_id = os.path.splitext(os.path.splitext(case)[0])[0]\n",
        "print(\"Visualizing:\", case_id)\n",
        "\n",
        "pred_img = nib.load(os.path.join(pred_dir, case))\n",
        "pred_data = pred_img.get_fdata()\n",
        "\n",
        "img_img = nib.load(os.path.join(input_dir, f\"{case_id}_0000.nii.gz\"))\n",
        "img_data = img_img.get_fdata()\n",
        "\n",
        "gt_img = nib.load(os.path.join(label_dir, f\"{case_id}.nii.gz\"))\n",
        "gt_data = gt_img.get_fdata()\n",
        "\n",
        "mid = img_data.shape[2] // 2\n",
        "\n",
        "overlay = np.zeros((*pred_data.shape, 3))\n",
        "overlay[pred_data == 1] = [1, 0, 0]\n",
        "overlay[pred_data == 2] = [0, 1, 0]\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img_data[:, :, mid], cmap=\"gray\")\n",
        "plt.title(\"Original CT\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(img_data[:, :, mid], cmap=\"gray\")\n",
        "plt.imshow(overlay[:, :, mid], alpha=0.5)\n",
        "plt.title(\"Segmentation Prediction\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(img_data[:, :, mid], cmap=\"gray\")\n",
        "plt.imshow(gt_data[:, :, mid], cmap=\"jet\", alpha=0.4)\n",
        "plt.title(\"Ground Truth\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2xX4uiwX563",
        "outputId": "559e7856-ea49-4ca0-adf4-105d981c965a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing: quiz_0_168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig(\"/content/drive/MyDrive/PC-Classifier/sample_visualization.png\", dpi=200)"
      ],
      "metadata": {
        "id": "cVvIP6C_ZdKk"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(pred, target, label):\n",
        "    pred_bin = (pred == label).astype(np.uint8)\n",
        "    target_bin = (target == label).astype(np.uint8)\n",
        "    intersection = np.sum(pred_bin * target_bin)\n",
        "    denom = np.sum(pred_bin) + np.sum(target_bin)\n",
        "    return (2. * intersection / denom) if denom > 0 else np.nan\n",
        "\n",
        "whole_pred = (pred_data > 0).astype(np.uint8)\n",
        "whole_gt = (gt_data > 0).astype(np.uint8)\n",
        "dsc_whole = dice_score(whole_pred, whole_gt, 1)\n",
        "\n",
        "dsc_lesion = dice_score(pred_data, gt_data, 2)\n",
        "\n",
        "print(f\"Whole pancreas DSC: {dsc_whole:.3f}\")\n",
        "print(f\"Pancreas lesion DSC: {dsc_lesion:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsXNLxcQcVzm",
        "outputId": "28e46ace-2c86-4839-f9e1-a4fd1b8d1ce0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole pancreas DSC: 0.874\n",
            "Pancreas lesion DSC: 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/PC-Classifier\"\n",
        "pred_dir = f\"{base_dir}/predictions_val\"\n",
        "gt_dir = f\"{base_dir}/nnUNet_raw/Dataset310_Pancreas/labelsVal\"\n",
        "\n",
        "def dice_score(pred, gt):\n",
        "    intersection = np.sum((pred > 0) & (gt > 0))\n",
        "    return (2.0 * intersection) / (np.sum(pred > 0) + np.sum(gt > 0) + 1e-8)\n",
        "\n",
        "results = []\n",
        "cases = sorted([f for f in os.listdir(pred_dir) if f.endswith(\".nii.gz\")])\n",
        "\n",
        "for case in cases:\n",
        "    case_id = os.path.splitext(os.path.splitext(case)[0])[0]\n",
        "    pred_file = os.path.join(pred_dir, case)\n",
        "    gt_file = os.path.join(gt_dir, f\"{case_id}.nii.gz\")\n",
        "\n",
        "    if not os.path.exists(gt_file):\n",
        "        print(\"锔 Missing ground truth for:\", case_id)\n",
        "        continue\n",
        "\n",
        "    pred = nib.load(pred_file).get_fdata()\n",
        "    gt = nib.load(gt_file).get_fdata()\n",
        "\n",
        "    whole_dsc = dice_score(pred > 0, gt > 0)\n",
        "    lesion_dsc = dice_score(pred == 2, gt == 2)\n",
        "    results.append([case_id, whole_dsc, lesion_dsc])\n",
        "\n",
        "df = pd.DataFrame(results, columns=[\"Case\", \"Whole_Pancreas_DSC\", \"Lesion_DSC\"])\n",
        "\n",
        "print(df)\n",
        "print(\"\\nAverage Results:\\n\", df[[\"Whole_Pancreas_DSC\", \"Lesion_DSC\"]].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dM4Zeswesn1",
        "outputId": "b45f0695-a435-4269-d335-723a67213dba"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Case  Whole_Pancreas_DSC  Lesion_DSC\n",
            "0   quiz_0_168            0.874281    0.011908\n",
            "1   quiz_0_171            0.886987    0.737191\n",
            "2   quiz_0_174            0.829151    0.650201\n",
            "3   quiz_0_184            0.932848    0.916279\n",
            "4   quiz_0_187            0.926402    0.340285\n",
            "5   quiz_0_189            0.923552    0.756631\n",
            "6   quiz_0_244            0.936325    0.421370\n",
            "7   quiz_0_253            0.920367    0.486115\n",
            "8   quiz_0_254            0.902114    0.225460\n",
            "9   quiz_1_090            0.848980    0.060250\n",
            "10  quiz_1_093            0.866815    0.776573\n",
            "11  quiz_1_094            0.935983    0.310248\n",
            "12  quiz_1_154            0.889943    0.000000\n",
            "13  quiz_1_158            0.908620    0.803649\n",
            "14  quiz_1_164            0.899609    0.895549\n",
            "15  quiz_1_166            0.932364    0.839276\n",
            "16  quiz_1_211            0.874290    0.628875\n",
            "17  quiz_1_213            0.903426    0.841381\n",
            "18  quiz_1_221            0.953211    0.794614\n",
            "19  quiz_1_227            0.914680    0.000000\n",
            "20  quiz_1_231            0.945854    0.594331\n",
            "21  quiz_1_242            0.933307    0.000000\n",
            "22  quiz_1_331            0.893210    0.023695\n",
            "23  quiz_1_335            0.920233    0.821231\n",
            "24  quiz_2_074            0.948543    0.870815\n",
            "25  quiz_2_080            0.936716    0.697407\n",
            "26  quiz_2_084            0.923531    0.850914\n",
            "27  quiz_2_085            0.929293    0.800543\n",
            "28  quiz_2_088            0.774661    0.000000\n",
            "29  quiz_2_089            0.882018    0.885896\n",
            "30  quiz_2_098            0.907120    0.859250\n",
            "31  quiz_2_191            0.747997    0.000000\n",
            "32  quiz_2_241            0.958289    0.612441\n",
            "33  quiz_2_364            0.878694    0.633799\n",
            "34  quiz_2_377            0.873241    0.826760\n",
            "35  quiz_2_379            0.953031    0.802966\n",
            "\n",
            "Average Results:\n",
            " Whole_Pancreas_DSC    0.901825\n",
            "Lesion_DSC            0.549331\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "          Case  Whole_Pancreas_DSC  Lesion_DSC\n",
        "0   quiz_0_168            0.874281    0.011908\n",
        "1   quiz_0_171            0.886987    0.737191\n",
        "2   quiz_0_174            0.829151    0.650201\n",
        "3   quiz_0_184            0.932848    0.916279\n",
        "4   quiz_0_187            0.926402    0.340285\n",
        "5   quiz_0_189            0.923552    0.756631\n",
        "6   quiz_0_244            0.936325    0.421370\n",
        "7   quiz_0_253            0.920367    0.486115\n",
        "8   quiz_0_254            0.902114    0.225460\n",
        "9   quiz_1_090            0.848980    0.060250\n",
        "10  quiz_1_093            0.866815    0.776573\n",
        "11  quiz_1_094            0.935983    0.310248\n",
        "12  quiz_1_154            0.889943    0.000000\n",
        "13  quiz_1_158            0.908620    0.803649\n",
        "14  quiz_1_164            0.899609    0.895549\n",
        "15  quiz_1_166            0.932364    0.839276\n",
        "16  quiz_1_211            0.874290    0.628875\n",
        "17  quiz_1_213            0.903426    0.841381\n",
        "18  quiz_1_221            0.953211    0.794614\n",
        "19  quiz_1_227            0.914680    0.000000\n",
        "20  quiz_1_231            0.945854    0.594331\n",
        "21  quiz_1_242            0.933307    0.000000\n",
        "22  quiz_1_331            0.893210    0.023695\n",
        "23  quiz_1_335            0.920233    0.821231\n",
        "24  quiz_2_074            0.948543    0.870815\n",
        "25  quiz_2_080            0.936716    0.697407\n",
        "26  quiz_2_084            0.923531    0.850914\n",
        "27  quiz_2_085            0.929293    0.800543\n",
        "28  quiz_2_088            0.774661    0.000000\n",
        "29  quiz_2_089            0.882018    0.885896\n",
        "30  quiz_2_098            0.907120    0.859250\n",
        "31  quiz_2_191            0.747997    0.000000\n",
        "32  quiz_2_241            0.958289    0.612441\n",
        "33  quiz_2_364            0.878694    0.633799\n",
        "34  quiz_2_377            0.873241    0.826760\n",
        "35  quiz_2_379            0.953031    0.802966\n",
        "\n",
        "Average Results:\n",
        " Whole_Pancreas_DSC    0.901825\n",
        "Lesion_DSC            0.549331\n",
        "dtype: float64"
      ],
      "metadata": {
        "id": "cihGJJJrg08M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "split_file = \"/content/drive/MyDrive/PC-Classifier/nnUNet_preprocessed/Dataset310_Pancreas/splits_final.json\"\n",
        "\n",
        "with open(split_file) as f:\n",
        "    splits = json.load(f)\n",
        "\n",
        "print(\"Fold 0 has\", len(splits[0]['val']), \"validation cases\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJDuFeRiflDK",
        "outputId": "e1cc8495-08cb-4bde-b963-4ad5d22e5f6f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 has 51 validation cases\n"
          ]
        }
      ]
    }
  ]
}